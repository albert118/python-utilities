#!/usr/bin/env python
# coding: utf-8

# # Test Data Generation

# ## Prerequisites:
# --------------------
# 
# It is assumed all customers (at least 1 is needed to run this) **have**,
# 
# ### Pro Subscription Status:
# * completed the PropertyMe setup,
#   * a dummy pro-subscription status is needed to complete this (and thus a dummy Visa), see [this link from Stripe](https://stripe.com/docs/testing#charges-api) on test cards.
# * `<add key="IsBypassingCheckStripeSubScription" value="true"/>` update this value in pM.ApiHost\Web.config as well as PropertyMe.ManagerApp.BusWorker\App.config
# 
# ### Various "Dummy Account" Values:
# * a dummy bank account attached (this is constant across the folios generated per customer),
# * a dummy address in JSON and single-line-text formats (this is fine as a constant per customer),
# 
# ### An Overriden Property Limit:
# * override the max-property limit of 200. **PROPERTIES > 200 WILL NOT BE CREATED AND DATA MAY NOT INSERT AS EXPECTED IF YOU SKIP THIS!**
# * Having already set `IsBypassingCheckStripeSubScription`, continue with this script and set the PROPERTY_LIMIT constant and proceed with the pre-setup sql execution to apply an UPDATE to the Subscription table.

# In[ ]:


import json
from collections import Counter

import numpy as np
import pandas as pd
import requests as r
from tqdm.auto import tqdm

from Auth import UserSession, UserSessionsHandler
from CommonLib import NotebookHelper, Stats, ConsoleHelpers
from CommonLib.Time import FunctionExecutionTimer
from Config import (ConfigureCsvFilename, ConfigureDbTableName,
                    ConfigureMySqlConnectionString, ConfigurePropertyMeBaseUrl)
from Database import *
from DataGeneration import ContactBuilder, DataGen, LotBuilder, TenancyBuilder


# ## Workflow:
# --------------------
# 1. Set Constants;
#    * This includes default values used herein.
# 2. Retrieve Filtered LoadTesting Users;
#    * These should already exist and be retrievable via SQL or be cached in a local csv.
#    * Authentication credentials must be included with each user.
# 3. Authenticate LoadTesting Users;
#    * Utilise the pre-generated credential(s) here.
#    * Mass authentication is triggered once all user sessions are constructed by the handler.
# 4. Update LoadTesting Users' Subscriptions (Prop-Limit Fix);
#    * Apply an UPDATE to all User's - unlocking their propertylimits.
# 5. Create and Insert Tenancy Data for Load Testing Customers;
#    * Create and utilise a 'meta' builder to step through all required entities. This enforces FK linkages.

# ## 1. Testing Data Constants
# --------------------
# 
# Here we define Constants for the Data Generation. This could easily be adapted to a csv or SQL reader to read potential customer load testers that are preconfigured.
# 
# ~~A Caveat at the moment is that CustomerID is a constant. Future changes should rectify this and make it dynamic for *wide testing*, as apposed to this single-customer "deep" test.~~
# 
# The `CloneArrearsAutomationTest` script/notebook duplicates the data generated by this script! Consider this as a precursor.

# In[ ]:


PROPERTY_LIMIT = 1000

customerID="'a7120162-fcc2-4ff6-9939-f48bd754df49'"

baseUrl = ConfigurePropertyMeBaseUrl()
fullFilenameDefault = 'deep-aa-load-test-customer-data'
fullFilename = None
dbString = None
divider = "********************************************************************************"
customers = pd.DataFrame()


# ## 2. Read (Filtered & Validated) Load Testing Customers
# --------------------

# In[ ]:


# Retrieve the load testing customer data
print(divider)
print('\nLOADING CUSTOMER DATA:')

csvExplanation = """
    The csv will require columns titled: CustomerId, Username, Pw, MessageTemplateId
    If these values are missing, then subsequent operations may fail unexpectedly.
    """

if not fullFilename:
    print("== CONFIGURING CSV ==")
    fullFilename = ConfigureCsvFilename(fullFilenameDefault)

    
if customers.empty:
    print(csvExplanation)
    print('\nREADING FROM CSV:')
    customers = pd.read_csv(fullFilename)

print('\nCustomer rows from file (customerId, username, messageTemplateId, memberId, managerId) (Password not shown):')
NotebookHelper.Output(customers.drop(["Pw"], axis=1).head())

ConsoleHelpers.PreventImmediateConsoleClose("**CHECK CUSTOMER DATA IS AS EXEPCTED**")
print(divider)


# ## 3. Authenticate Load Testing Customers
# --------------------

# In[ ]:


# Configure the load testing 'customer' authentication sessions.
print(divider)
print('\nAUTHENTICATING AND OBTAINING SESSION DATA FOR EACH CUSTOMER:')

def MakeSession(s: pd.Series, handler: UserSessionsHandler):
    """Functional approach is a neat way to easily auth users in a dataframe."""
    return handler.AddUserSession(s.Username, s.Pw)

pmeHandler = UserSessionsHandler(baseUrl)
customers.apply(lambda c: MakeSession(c, pmeHandler), axis=1)
pmeHandler.AuthenticateSessions()

print('\n\n**CHECK CUSTOMER DATA IS ALL EXPECTED**')
print(f"{len(pmeHandler.Sessions)} sessions were created.")
print(f"Session summary:\t{pmeHandler.Sessions[:5]}")
endSectionMessage = "To re-execute the script and start again, close the program via the window [x] button."
ConsoleHelpers.PreventImmediateConsoleClose(endSectionMessage)

print(divider)


# ## 4. Update Load Testing Customers' Prop-Limit
# --------------------

# In[ ]:


# Update the customers property limits
updateData = dict()
if not dbString:
    dbString = ConfigureMySqlConnectionString()

# functional approach is a neat way to easily propogate updatedata for users in a dataframe
def AddCustomerUpdateData(s: pd.Series, updateData: dict):
    global PROPERTY_LIMIT
    updateData[s.CustomerId] = { "PropertyLimit": PROPERTY_LIMIT }
    return

customers.apply(lambda c: AddCustomerUpdateData(c, updateData), axis=1)

print(f"Data to be UPDATED {updateData}\n")
input("'Enter' to continue...")

UpdateTableDataForCustomers(dbString, "subscription", updateData)


# 
# ## 5. Create and Insert Tenancy Data for Load Testing Customers
# --------------------
# 
# ### To insert test data for a tenancy,
# 1. Generate a unique contact and lot (using dummy address) per n records (lot then record);
# 2. Generate a folio entry for each new contact (using bank account);
# 3. Given generated folio ID, generate a unique tenancy per folio entry (IDs of folio and tenancy are linked FK / PK - weird I know);
# 

# ### Controlling the days in arrears per tenant
# 
# Days in arrears are calculated with the following code snippet, in our data generation we dont set the `lastEffPaidTo` field. Hence, the second formula is how Days in Arrears will be calculated.
# 
# ``` C#
# var lastEffPaidTo = db.Scalar<RentPaid, DateTime?>(RP => Sql.Max(RP.EffectivePaidTo), 
#                                                    RP => RP.TenancyId == item.TenancyId
#                                                    && RP.JournalNumber < item.JournalNumber 
#                                                    && RP.EffectivePaidTo != null);
# if (lastEffPaidTo != null)
#     rentPaid.ArrearsDays = (rentPaid.PaidOn - lastEffPaidTo.Value).Days;
# else
#     rentPaid.ArrearsDays = (rentPaid.PaidOn - tenancy.TenancyStart.AddDays(-1)).Days;
# ```
# 
# *ArrearsDays* = *rentPaid.PaidOn* - *lastEffectivePaidTo* **or** *ArrearsDays* = *rentPaid.PaidOn* - *tenancy.TenancyStart* - *1 day*

# ### Generator Configuration
# 
# Here we utilise the constants set previously and define new `builders` for each entity-type to generate. The resultant generators are returned in a dict keyed by the entity they generate. Given this generator configuration, each entity needs to be produced in relative order. So, we define a meta-generator to 'step' each entity in the correct order. This is important, as this process must be considered atomic to avoid network race conditions. e.g. `POST`'ing a lot and contact to build a tenancy submits the tenancy first and then lot and contact would result in undefined behaviour (typically the tenancy would resolve to empty guids on its contact and lot).

# In[ ]:


# TODO: Extract me! This is a pretty common concept that should be reusable
class PropertyMetaBuilder:
    def __init__(self, customerId: str, managerId: str, session: UserSession, n=10):
        self._customerID = customerId
        self._managerID = managerId
        self._tenancyIDs = list()
        self._session = session
        # num iters
        self._n = n
        
        # configure days in arrears
        self._ConfigureDaysInArrears()
        # configure the generators for dependent entities
        self._SetupGenerators()

    def _SetupGenerators(self):
        # set-up the relavent builders
        lBuilder = LotBuilder(self._customerID, self._managerID)
        cBuilder = ContactBuilder(self._customerID)
        tBuilder = TenancyBuilder(self._customerID)
        
        # set-up the relavent generators
        self._lotGen = DataGen(builder=lBuilder)
        self._contactGen = DataGen(builder=cBuilder)
        self._tenancyGen = DataGen(builder=tBuilder)

    def _ConfigureDaysInArrears(self):
        """ArrearsDays = rentPaid.PaidOn - tenancy.TenancyStart - 1 day"""
        
        # mean and standard deviation, these should be estimated from actual data!
        mu, sigma = 6, 1
        # remove -1 as this cancels our calculation out! It will throw an error!
        # OK I have no idea why -8 throws it...but it does
        filterOutputRange = (-1, -8)
        # negative days in arrears are what matters here
        self._zdist = Stats.Integer_ZDistribution(mu, sigma, self._n, negativeDist=True, filterOutputRange=filterOutputRange)
        
        # verify the dataset looks correct
        Stats.GraphHistogramWithOverlay(self._zdist, "Days in Arrears Test Dataset")
        input("**Assert distribution and dataset are valid**.\nEnter to continue...")
        
    def Step(self):
        # Contact and Lot are base entities. Generate these first
        contact = InsertApi(self._session, self._contactGen.next(), "contacts")
        
        if contact is None:
            print("SKIPPING | Duplicate Contact entity")
            return
        
        contactID = contact["ContactId"]
        
        lot = InsertApi(self._session, self._lotGen.next(), "lots")
        
        if lot is None:
            print("SKIPPING | Duplicate Lot entity")
            return
        
        lotID = lot["LotId"]
        
        # Build the tenancy using it's dependencies
        unsavedTenancy = self._tenancyGen.next(lotID=lotID, contactID=contactID, daysInArrears=self._zdist.pop())
        tenancy = InsertApi(self._session, unsavedTenancy, "tenancies")
        
        if tenancy is None:
            print("SKIPPING | Duplicate Tenancy entity")
            return
        
        
        # If any insertion errors occur, print the entity return (incl. StackTrace)
        if not contact['IsSuccessful']:
            print(contact)
            
        if not lot['IsSuccessful']:
            print(lot)
            
        if not tenancy['IsSuccessful']:
            print(tenancy)
        
        self._tenancyIDs.append(tenancy["TenancyId"])
        
    @property
    def TenancyIDs(self):
        return self._tenancyIDs
    
    @property
    def UnsuccessfulGenerations(self):
        # This is actually simpler than including a counter manually when the entity 
        # POST returns empty guids.
        return Counter(self._tenancyIDs)["00000000-0000-0000-0000-000000000000"]
        
    @FunctionExecutionTimer()
    def RunBuilder(self):
        print("Running test data insertion, this will take awhile.")
        # tqdm will create a progress bar to monitor execution progress.
        for i in tqdm(range(self._n)):
            # if the step finds an existing ID it will return and begin the next step
            metaBuilder.Step()
    
        print(f"{len(self.TenancyIDs)} where created.")
        print(f"{self.UnsuccessfulGenerations} failed!\n")


# In[ ]:


# TODO: Extract me! This is a pretty common concept that should be reusable
def InsertApi(session: UserSession, entity: str, entityName: str) -> str:
    """Insert (POST) an Entity to the PME API at a given baseUrl.
    
    Args
    ----
    
    session: UserSession,
        The authenticated session to POST with.
    
    entity: str,
        The entity name utilised by the API routing. This can be found from the PME controller.
        
    TBD
    baseUrl: str,
        The PME API base address to build the endpoint URL from. e.g.,
        
        "local": "http://localhost:8080",
        "dev1": "https://app-dev1.sandbox.propertyme.com",
        "stage": "https://stage.propertyme.com",
        
        See ConfigurePropertyMeUrl for more examples.
        
    Returns
    -------
    
    res: Json,
        A json result from the endpoint.
    """
    
    global baseUrl
    
    # UserSession should have configured credentials, incl. cookies and the default headers
    apiEndpoint = f"{baseUrl}/api/entity/{entityName}?format=json"
    headers = {"content-type": "application/json"}
    res = session.Current.post(apiEndpoint, data=entity, headers=headers)
    
    if (res.status_code == 500):
        return None
    elif res.text is not None:
        return json.loads(res.text)
    else:
        return ''


# In[ ]:


# Data to run test - this is a hardcoded read of the first row!!
customer = customers.iloc[0]

metaBuilder = PropertyMetaBuilder(
    customerId=customer.name,
    managerId=customer.ManagerId, 
    session=pmeHandler.Sessions[0],
    n=PROPERTY_LIMIT
)

metaBuilder.RunBuilder()
ConsoleHelpers.PreventImmediateConsoleClose('Complete! Please review the logs to ensure the insertion was as intended. Hit "Enter" immediately to close console.')


# In[ ]:




